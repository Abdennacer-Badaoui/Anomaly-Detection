{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection with autoencoder\n",
    "\n",
    "Today, we will detect anomalies in another dataset containing devices logs. The devices are supposed to send a payload every hour. As we will see, some devices disappear from the network from time to time. We will build an algorithm to predict these failures: an autoencoder.  \n",
    "An autoencore is a particular type of Feedforward Neural Networks (FNN). So, let us first have a look on what a FNN is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network \n",
    "\n",
    "The explanations on FNN are given in the PDF file \"FNN-intro.pdf\". Try to understand the main ideas in this paper, but we keep in mind that the topic of Neural Nework is very large and can be difficult to fully understand \n",
    "at first sight.\n",
    "\n",
    "Here is a summary of the PDF.\n",
    "\n",
    "The FNN aims to build a **prediction function** based on a **labelled data set**.\n",
    "The data set $D$ is composed of points $p=(x,y)$ where $x \\in \\mathbb{R}^{I}$ is the \"input\" and $y \\in \\mathbb{R}^{O}$ is the \"label\" (or output). For example, the MNIST data base is composed of $x$ values that are tables of $28 \\times 28 = 784$ pixels that represent a black and white handwritten digit and of $y$ values of digits represented as an array of $9$ zeros with a $1$ in the index that corresponds to the written digit. For example a $3$ will be represented as $[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]$.\n",
    "\n",
    "A FNN is composed of an input layer, of $(L-1)\\in \\mathbb{N}$ hidden layers and of an output layer. We note the dimension of layer $l$ as $n_l$.  \n",
    "For coherence with the data, we have that the first layer ($l=0$) is of the same size that the input and the last layer ($l=L$) is of the size of the output. So, we have $n_0=I$ and $n_L=O$.\n",
    "\n",
    "<img src=\"./images/FNN.jpg\" alt=\"FNN\" width=\"500\"/>\n",
    "(src: https://neuralnetworksanddeeplearning.com/chap1.html)\n",
    "\n",
    "#### Feedforward\n",
    "\n",
    "Let us take a point $p=(x,y)$ where $x$ is the input and $y$ is the label (output, the result to predict).\n",
    "The prediction is the value of the last layer.\n",
    "\n",
    "The fist layer is equal to the input\n",
    "\n",
    "$$\n",
    "a^{(0)} = x\n",
    "$$\n",
    "\n",
    "The value of the layer $l$ is a function of the previous layer $(l-1)$, defined as \n",
    "\n",
    "$$\n",
    "z^{(l)}_j = \\sum_{k} w^{(l)}_{jk} a^{(l-1)}_k + b^{(l)}_j\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{(l)}_j = \\sigma(z^{(l)}_j)\n",
    "$$\n",
    "\n",
    "or in matrix notation,\n",
    "$$\n",
    "a^{(l)} = \\sigma ( w^{(l)} \\cdot a^{(l-1)} + b^{(l)}).\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the activation function. Here we will use the sigmoid function,\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}.\n",
    "$$\n",
    "We can simply compute the derivative function\n",
    "$$\n",
    "\\sigma '(z) =  \\frac{e^{-z}}{(1 + e^{-z})^{2}} = \\sigma(z) (1 - \\sigma(z)).\n",
    "$$\n",
    "\n",
    "\n",
    "#### Learning\n",
    "\n",
    "The process of learning starts with randomly initialized parameters $P=(w,b)$ (weights and biases). Then at each step (this step is called an **epoch**), we adjust the parameters to $P \\rightarrow P'$ that will give a better prediction on the training data.\n",
    "\n",
    "For that purpose we define the **error** as the distance between the label valyes $y$ and the prediction $a^{L}$.  \n",
    "Here is the value of the error for one point $p$. \n",
    "$$\n",
    "C_p = \\sum_{j=0}^{n_L -1} (a^{(L)}_j - y_j)^2\n",
    "$$\n",
    "The total error is the mean of all the errors, \n",
    "\n",
    "$$\n",
    "C = \\frac{1}{|D|} \\sum_{p \\in D} C_p\n",
    "$$\n",
    "\n",
    "This adjustment is done by the **gradient descent**. The idea is to adjust the parameters in the **direction that minimize the most the error**. The direction that locally minimise the error is the direction of the negative gradient of $C$ with respect to the parameters $P$.  \n",
    "So, at each epoch we adjust the parameters as\n",
    "\n",
    "$$ P' = P - \\alpha \\nabla C,$$\n",
    "\n",
    "where $\\alpha$ is the **learning rate**. It defines how fast the parameters will be adjusted.  \n",
    "\n",
    "Note that the gradient is the vector of the partial derivatives: \n",
    "\n",
    "$$\n",
    "\\nabla C = \\left(\\frac{\\partial C}{\\partial w^{(1)}_{11}}, \\dots, \\frac{\\partial C}{\\partial b^{(1)}_1}, \\dots \\right)\n",
    "$$\n",
    "\n",
    "Here, we provide you, by omitting computation, the equations that gives us the gradient,\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial C_p}{\\partial w^{(l)}} & = \n",
    "\\frac{\\partial C_p}{\\partial z^{(l)}} \\cdot (a^{(l-1)})^{T} , \\\\\n",
    "\\frac{\\partial C_p}{\\partial b^{(l)}} & = \n",
    "\\frac{\\partial C_p}{\\partial z^{(l)}}, \\\\\n",
    "\\frac{\\partial C_p}{\\partial z^{(L)}} & = 2 (a^{(L)} - y) \\odot \\sigma ' (z^{(L)}), \\\\\n",
    "\\frac{\\partial C_p}{\\partial z^{(l)}} & =\n",
    "\\left( (w^{(l+1)})^{T} \\cdot \\frac{\\partial C_p}{\\partial z^{(l+1)}} \\right) \\odot \\sigma ' (z^{(l)})  && l < L.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "\n",
    "An autoencoder (AE) is a type of neural network that gets an input and learns to rebuild it, instead of mapping this input to an ouput as a classical NN would do.\n",
    "\n",
    "Moreover, we generally assume that the hidden layers are smaller than the input/output layers. So it will in fact **compress** the data and then **decompress** it again to try to reconstruct the inital input.\n",
    "\n",
    "This seems to be useless, however scientists have found some ways to use it. One of them is the **Outlier Detection**. The idea is the following, first it learns the **autoencode the data**, then each point is sent by the feedforward to its image and we compute its loss (error),\n",
    "\n",
    "$$\n",
    "C_x = |x - x'|Â².\n",
    "$$\n",
    "\n",
    "The points with a **high loss** are those who are **not well reconstructed** by the Autoencoder and so they can be seen as **outliers**. \n",
    "\n",
    "![AE](./images/Toad.png)\n",
    "\n",
    "(src: https://medium.com/themlblog/deep-autoencoders-using-tensorflow-4f68655c8d08)\n",
    "\n",
    "The idea behind the use of AE as anomaly detection algorithm is quite simple:\n",
    "\n",
    "- an AE that has been trained on inliners will be able to rebuild inliners but not outliers;\n",
    "- the preparation of the data to train an AE is often more straightforward: a classical neural network will require supervision, aka a labeled dataset (with label that actually make sense) while an AE is unsupervised and can be directly used to compute the difference between the input and the output.\n",
    "\n",
    "We will build our autoencoders using \"dummy\" training data points. We have generated randomly distributed normal data of size 300 in 3 dimensions. We use this data instead of logs to make sure our algorithm learns while keeping the computations very fast.\n",
    "\n",
    "We will implement our AE using PyTorch (https://pytorch.org/). PyTorch offers many tools to implement algorithms, ranging from low level functions (ex: matrices multiplication, broadcasting) to pre-made networks expecting only a forward method (eg: https://pytorch.org/tutorials/beginner/nn_tutorial.html#switch-to-cnn).\n",
    "\n",
    "We will go for the low level implementation. The PyTorch low level are the same as numpy's ones, except that `np.ndarray` is replaced by `torch.Tensor`. The syntax of matrix multiplications, element wise addition/multiplication etc. are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**  \n",
    "\n",
    "These are quite simple models of FNN and Autoencoder and they are far from the current state of art.\n",
    "\n",
    "The implementation that we propose here is certainly not a good way to do Outlier Detection with Autoencoder. To do it well we should spend much more time to specify our Autoencoder activation function, error (loss) function and a large set of different variations that we can apply to a Neural Network. The aim here is to present the global idea about how a Neural Network can be usefull in an unusual context and at the same time a very clever way to do Outlier Detection. Isn't that amazing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to change the content of this cell\n",
    "# load the modules we need\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import Any, List, Optional, Tuple, Union\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to change the content of this cell\n",
    "# load the training data\n",
    "training_data = torch.load('./data/training_data_points.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some guidelines to implement the autoencoder. We will create 4 python classes:\n",
    "    \n",
    "1) Network: contains the methods that are common to both a classical Neural Network and an autoencoder.\n",
    "\n",
    "2) Autoencoder: contains the methods that are proper to an autoencoder.\n",
    "    \n",
    "3) Sigmoid: the sigmoid activation function which we will use for *all* layers except the output layer. \n",
    "    \n",
    "    Since the principle of a NN is a gradient descent due to the feedforward and backpropagation functions, our ActivationFunction class will have two methods: compute and differentiate. The same holds true for the CostFunction.\n",
    "\n",
    "    Note that frameworks like PyTorch and Tensorflow use a Layer class that allows you to use a different activation function for each layer (along with other transformations like dropouts, masks, etc. that are out of the scope of this TD). For the sake of clarity, we will use the sigmoid activation function for all layers and pass it to the __init__ method of the Network class.\n",
    "   \n",
    "4) Mean squared error: the cost function we will apply to the output layer.\n",
    "\n",
    "Refer to the pdf when implemeing your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to change the content of this cell\n",
    "# here we define abstract classes for the activation and cost functions\n",
    "# our clases will inherit their methods\n",
    "\n",
    "class ActivationFunction(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def differentiate(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "class CostFunction(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def differentiate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST CHANGE THE CONTENT OF THIS CELL\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, z: torch.Tensor) -> torch.Tensor:\n",
    "        # complete this\n",
    "        return 1/(1+torch.exp(-z))\n",
    "\n",
    "    @classmethod\n",
    "    def differentiate(cls, z: torch.Tensor) -> torch.Tensor:\n",
    "        # complete this\n",
    "        return Sigmoid.compute(z)*(1-Sigmoid.compute(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the mean squared error as our cost function: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST CHANGE THE CONTENT OF THIS CELL\n",
    "\n",
    "class MSE(CostFunction):\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, a: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # complete this\n",
    "        return torch.norm((a-y)**2)\n",
    "    @classmethod\n",
    "    def differentiate(cls, a: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        return 2*(a-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement the Network class. You must complete the feedforward, backprop and GD methods.\n",
    "\n",
    "The formulas are in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST CHANGE THE CONTENT OF THIS CELL\n",
    "\n",
    "class Network(ABC):\n",
    "    \n",
    "    def __init__(self, activation_function:ActivationFunction, cost_function:CostFunction, *layers:int) -> None:\n",
    "        self.weights = [\n",
    "            torch.rand(y, x, dtype=torch.float64) for x, y in zip(layers[:-1], layers[1:])\n",
    "        ]\n",
    "        self.biases = [\n",
    "            torch.rand(y, 1, dtype=torch.float64) for y in layers[1:]\n",
    "        ]\n",
    "        self.activation_function = activation_function\n",
    "        self.cost_function = cost_function\n",
    "        \n",
    "    @classmethod\n",
    "    def get_batches(cls, X:List[torch.Tensor], Y:List[torch.Tensor], batch_size:int) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        training_data = list(zip(X, Y))\n",
    "        random.shuffle(training_data)\n",
    "        X, Y = zip(*training_data)\n",
    "        batchesX, batchesY = [], []\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batchesX.append(X[i:i+batch_size])\n",
    "            batchesY.append(Y[i:i+batch_size])\n",
    "        return batchesX, batchesY\n",
    "    \n",
    "    def feedforward(self, a:torch.Tensor) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        # layers (activation)\n",
    "        aL = [a]\n",
    "        # layers (linear)\n",
    "        zL = [a]\n",
    "        # COMPLETE THIS\n",
    "        for b, w in zip(self.biases,self.weights):\n",
    "            zL.append(torch.tensordot(w, zL[-1],1)+b)\n",
    "            aL.append(Sigmoid.compute(zL[-1]))\n",
    "        return aL, zL\n",
    "    \n",
    "    def backprop(self, x:List[torch.Tensor], y:List[torch.Tensor], aL:List[torch.Tensor], zL:List[torch.Tensor]) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        # initialize the gradient for this epoch\n",
    "        dw = [torch.zeros(w.shape, dtype=torch.float64) for w in self.weights]\n",
    "        db = [torch.zeros(b.shape, dtype=torch.float64) for b in self.biases]\n",
    "        # COMPLETE THIS\n",
    "        delta=2*(aL[-1]-y)*Sigmoid.differentiate(zL[-1])\n",
    "        db[-1]=delta\n",
    "        dw[-1]=torch.tensordot(delta,torch.t(aL[-2]),1)\n",
    "        for l in range(2,len(layers)):\n",
    "            z=zL[-l]\n",
    "            sp=Sigmoid.differentiate(z)\n",
    "            delta=torch.tensordot(torch.transpose(self.weights[-l+1],0,1),delta,1)*sp\n",
    "            db[-l]=delta\n",
    "            dw[-l]=torch.tensordot(delta,torch.t(aL[-l-1]),1)\n",
    "        \n",
    "        return dw, db\n",
    "    \n",
    "    def GD(self, X:Tuple[torch.Tensor], Y:Tuple[torch.Tensor], alpha:float) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        # initialize gradients\n",
    "        Edw = [torch.zeros(w.shape, dtype=torch.float64) for w in self.weights]\n",
    "        Edb = [torch.zeros(b.shape, dtype=torch.float64) for b in self.biases]\n",
    "        # descent\n",
    "        for (x, y) in zip(X, Y):\n",
    "            # feed forward\n",
    "            aL, zL = self.feedforward(x)\n",
    "            # backprop\n",
    "            dw, db = self.backprop(x, y, aL, zL)\n",
    "            # gradient update\n",
    "            # COMPLETE THIS\n",
    "        \n",
    "            Edw = [edw+dnw for edw, dnw in zip(Edw, dw)]\n",
    "            Edb = [edb+dnb for edb, dnb in zip(Edb, db)]\n",
    "                \n",
    "            \n",
    "            \n",
    "        return Edw, Edb\n",
    "    \n",
    "    def update_weigths_and_biases(self, Edw:List[torch.Tensor], Edb:List[torch.Tensor]) -> None:\n",
    "        # apply\n",
    "        \n",
    "        self.weights = [w-0.12*dw_l for w, dw_l in zip(self.weights, Edw)]\n",
    "        self.biases  = [b-0.12*db_l for b, db_l in zip(self.biases , Edb)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder class imply defines a train method and a few helpers for outliers detection.\n",
    "\n",
    "Note the `self.GD(x, x, alpha)` line, where the training data is passed both as input and ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to change the content of this cell\n",
    "\n",
    "class Autoencoder(Network):\n",
    "\n",
    "    def autoencode(self, x) -> int:\n",
    "        aL, zL = self.feedforward(x)\n",
    "        return torch.norm(aL[-1] - x) ** 2\n",
    "    \n",
    "    def train(self, X:List[torch.Tensor], epochs:int=100, alpha:float=0.5, batch_size:int=100, test_data=None,\n",
    "                  printEach:int=1, median:int=2, treshold:int=2) -> None:\n",
    "        history = []\n",
    "        for i in range(epochs):\n",
    "            # stochastic?\n",
    "            bacthX = self.get_batches(X, X, batch_size)[0] if batch_size else [X]\n",
    "            for x in bacthX:\n",
    "                Edw, Edb = self.GD(x, x, alpha)\n",
    "                self.update_weigths_and_biases(Edw, Edb)\n",
    "            # Print\n",
    "            if(i%printEach == 0):\n",
    "                if(test_data):\n",
    "                    prediction = self.predict(X)\n",
    "                    print(\"Epoch \", i, \" of \", epochs, \"  -> Average Distance: \", prediction)\n",
    "                    history.append(prediction)\n",
    "                else:\n",
    "                    print(\"Epoch \", i, \" of \", epochs)\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        dist = 0\n",
    "        for x in X:\n",
    "            dist += self.autoencode(x)\n",
    "        return float(dist/len(X))\n",
    "    \n",
    "    def discriminate(self, data, treshold):\n",
    "        inlayer = []\n",
    "        outliers = []\n",
    "        for element in data:\n",
    "            if(self.autoencode(element) < treshold):\n",
    "                inlayer.append(element)\n",
    "            else:\n",
    "                outliers.append(element)\n",
    "        print(len(outliers), \"outliers over \", len(data))\n",
    "        return inlayer, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# you do not need to change the content of this cell\n",
    "\n",
    "dim = 3\n",
    "layers = [dim, dim-1,dim-1, dim]\n",
    "print(len(layers))\n",
    "autoencoder = Autoencoder(Sigmoid, MSE, *layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  of  400   -> Average Distance:  0.3283694819695554\n",
      "Epoch  10  of  400   -> Average Distance:  0.07895165603826258\n",
      "Epoch  20  of  400   -> Average Distance:  0.0792048426286913\n",
      "Epoch  30  of  400   -> Average Distance:  0.0762628113647279\n",
      "Epoch  40  of  400   -> Average Distance:  0.06964351085499726\n",
      "Epoch  50  of  400   -> Average Distance:  0.05191859738218088\n",
      "Epoch  60  of  400   -> Average Distance:  0.03927460996202404\n",
      "Epoch  70  of  400   -> Average Distance:  0.033474017676674704\n",
      "Epoch  80  of  400   -> Average Distance:  0.03279100883587996\n",
      "Epoch  90  of  400   -> Average Distance:  0.032708056232573904\n",
      "Epoch  100  of  400   -> Average Distance:  0.03222691353343048\n",
      "Epoch  110  of  400   -> Average Distance:  0.03198153703449594\n",
      "Epoch  120  of  400   -> Average Distance:  0.03181446132648713\n",
      "Epoch  130  of  400   -> Average Distance:  0.0316565466192217\n",
      "Epoch  140  of  400   -> Average Distance:  0.031459606763814964\n",
      "Epoch  150  of  400   -> Average Distance:  0.03103240395909815\n",
      "Epoch  160  of  400   -> Average Distance:  0.030712707373794952\n",
      "Epoch  170  of  400   -> Average Distance:  0.030283185543443912\n",
      "Epoch  180  of  400   -> Average Distance:  0.029490498964644517\n",
      "Epoch  190  of  400   -> Average Distance:  0.028821994658561844\n",
      "Epoch  200  of  400   -> Average Distance:  0.02744515796754578\n",
      "Epoch  210  of  400   -> Average Distance:  0.02638627541174951\n",
      "Epoch  220  of  400   -> Average Distance:  0.02436713627495104\n",
      "Epoch  230  of  400   -> Average Distance:  0.022438444455152737\n",
      "Epoch  240  of  400   -> Average Distance:  0.02100300267199164\n",
      "Epoch  250  of  400   -> Average Distance:  0.020459878831403787\n",
      "Epoch  260  of  400   -> Average Distance:  0.019824249985482264\n",
      "Epoch  270  of  400   -> Average Distance:  0.019488813912002665\n",
      "Epoch  280  of  400   -> Average Distance:  0.019747730581017007\n",
      "Epoch  290  of  400   -> Average Distance:  0.019343490544578935\n",
      "Epoch  300  of  400   -> Average Distance:  0.01936090928911456\n",
      "Epoch  310  of  400   -> Average Distance:  0.019504932426657948\n",
      "Epoch  320  of  400   -> Average Distance:  0.019333799089204226\n",
      "Epoch  330  of  400   -> Average Distance:  0.019369923957644267\n",
      "Epoch  340  of  400   -> Average Distance:  0.019316549476114466\n",
      "Epoch  350  of  400   -> Average Distance:  0.019303032799658875\n",
      "Epoch  360  of  400   -> Average Distance:  0.019372115286182677\n",
      "Epoch  370  of  400   -> Average Distance:  0.019393042394863783\n",
      "Epoch  380  of  400   -> Average Distance:  0.01930064231031018\n",
      "Epoch  390  of  400   -> Average Distance:  0.01927456568072414\n",
      "CPU times: user 1min 19s, sys: 0 ns, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# you do not need to change the content of this cell\n",
    "\n",
    "# Train autoencoder\n",
    "history = autoencoder.train(training_data, epochs=400, alpha=0.5, batch_size=128, test_data=training_data, printEach=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you do not need to change the content of this cell\n",
    "\n",
    "plt.plot(history, linewidth=2, label='Loss on training data')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[1,2,3],[4,5,6]])\n",
    "y=torch.tensor([1,1,1])\n",
    "\n",
    "print(torch.tensordot(x,y,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
